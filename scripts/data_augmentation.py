import logging
import random
from pathlib import Path
from typing import Tuple, List

import numpy as np
import torch
from PIL import Image
from torchvision import transforms
from torchvision.transforms import AutoAugment, AutoAugmentPolicy

# ------------------------------------------------------------
# æ—¥å¿—é…ç½®
# ------------------------------------------------------------
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# ============================================================
# CIFAR-Friendly å›¾åƒå¢å¼ºå™¨
# ============================================================
class ImageAugmenter:
    """
    CIFAR æ•°æ®å¢å¼ºå™¨ï¼š
      - RandomCrop(32, padding=4)
      - RandomHorizontalFlip(0.5)
      - AutoAugment(CIFAR10 Policy)
      - ToTensor + Normalize
      - RandomErasing(p=0.25)
      - æ”¯æŒ Mixup / CutMixï¼ˆbatchçº§æ¥å£ï¼‰
    """

    def __init__(
        self,
        augmentations_per_image: int = 3,
        seed: int = 42,
        save_original: bool = True,
        image_extensions: Tuple[str, ...] = (".png", ".jpg", ".jpeg"),
        dataset: str = "cifar100",  # ğŸ”¹ æ–°å¢ï¼šæ ¹æ®æ•°æ®é›†é€‰æ‹© mean/std
    ):
        self.augmentations_per_image = augmentations_per_image
        self.seed = seed
        self.save_original = save_original
        self.image_extensions = image_extensions
        self.dataset = dataset.lower()

        self._set_seed()

        # ----------------------------------------------------
        # æŒ‰æ•°æ®é›†ç±»å‹è®¾ç½®å‡å€¼å’Œæ ‡å‡†å·®
        # ----------------------------------------------------
        if self.dataset == "cifar10":
            mean = (0.4914, 0.4822, 0.4465)
            std = (0.2470, 0.2435, 0.2616)
        else:  # é»˜è®¤ä½¿ç”¨ CIFAR-100 å‚æ•°
            mean = (0.5071, 0.4867, 0.4408)
            std = (0.2675, 0.2565, 0.2761)

        # ----------------------------------------------------
        # è®­ç»ƒé˜¶æ®µæ•°æ®å¢å¼º pipeline
        # ----------------------------------------------------
        self.transform = transforms.Compose([
            transforms.RandomCrop(32, padding=4),
            transforms.RandomHorizontalFlip(p=0.5),
            AutoAugment(policy=AutoAugmentPolicy.CIFAR10),
            transforms.ToTensor(),
            transforms.Normalize(mean, std),
            transforms.RandomErasing(p=0.25)
        ])

        # ----------------------------------------------------
        # éªŒè¯/æµ‹è¯•é˜¶æ®µ pipelineï¼ˆæ— éšæœºæ€§ï¼‰
        # ----------------------------------------------------
        self.eval_transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize(mean, std)
        ])

    # ========================================================
    # å†…éƒ¨è¾…åŠ©å‡½æ•°
    # ========================================================
    def _set_seed(self):
        """å›ºå®šéšæœºç§å­ï¼Œä¿è¯å¤ç°æ€§"""
        random.seed(self.seed)
        np.random.seed(self.seed)
        torch.manual_seed(self.seed)
        if torch.cuda.is_available():
            torch.cuda.manual_seed_all(self.seed)

    def _find_image_files(self, root: Path) -> List[Path]:
        """é€’å½’æŸ¥æ‰¾å›¾ç‰‡æ–‡ä»¶"""
        files = []
        for ext in self.image_extensions:
            files.extend(root.rglob(f"*{ext}"))
        return files

    # ========================================================
    # å›¾åƒçº§å¢å¼ºæ¥å£ï¼ˆä¿æŒåŸç»“æ„ï¼‰
    # ========================================================
    def augment_image(self, image: Image.Image) -> torch.Tensor:
        """å¯¹å•å¼ å›¾åƒæ‰§è¡Œå¢å¼ºï¼Œè¿”å›å¢å¼ºå Tensor"""
        return self.transform(image)

    def process_directory(self, input_dir: str, output_dir: str) -> None:
        """
        æ‰¹é‡å¢å¼º input_dir ä¸‹çš„å›¾ç‰‡å¹¶ä¿å­˜åˆ° output_dirã€‚
        å…¼å®¹åŸ main.py è°ƒç”¨æ–¹å¼ã€‚
        """
        input_path = Path(input_dir)
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        count = 0

        image_files = self._find_image_files(input_path)
        logger.info(f"Found {len(image_files)} images to augment.")

        for img_path in image_files:
            try:
                image = Image.open(img_path).convert("RGB")
            except Exception as e:
                logger.warning(f"Failed to load image {img_path}: {e}")
                continue

            rel_dir = img_path.parent.relative_to(input_path)
            target_dir = output_path / rel_dir
            target_dir.mkdir(parents=True, exist_ok=True)

            # ä¿å­˜åŸå›¾
            if self.save_original:
                orig_name = f"orig_{img_path.name}"
                image.save(target_dir / orig_name)

            # ç”Ÿæˆå¢å¼ºæ ·æœ¬
            for i in range(self.augmentations_per_image):
                augmented_tensor = self.transform(image)
                augmented_img = transforms.ToPILImage()(augmented_tensor)
                aug_name = f"aug_{i}_{img_path.name}"
                augmented_img.save(target_dir / aug_name)
                count += 1

        logger.info(f"Data augmentation completed. {count} images saved to {output_dir}")


# ============================================================
# Mixup / CutMix å·¥å…·å‡½æ•°ï¼ˆä¾› train_utils.py è°ƒç”¨ï¼‰
# ============================================================
def mixup_data(x, y, alpha=1.0, device="cuda"):
    """æ‰¹æ¬¡çº§ Mixup"""
    if alpha > 0:
        lam = np.random.beta(alpha, alpha)
    else:
        lam = 1.0
    batch_size = x.size()[0]
    index = torch.randperm(batch_size).to(device)
    mixed_x = lam * x + (1 - lam) * x[index, :]
    y_a, y_b = y, y[index]
    return mixed_x, y_a, y_b, lam


def cutmix_data(x, y, alpha=1.0, device="cuda"):
    """æ‰¹æ¬¡çº§ CutMix"""
    if alpha > 0:
        lam = np.random.beta(alpha, alpha)
    else:
        lam = 1.0
    batch_size, _, H, W = x.size()
    index = torch.randperm(batch_size).to(device)
    cut_rat = np.sqrt(1. - lam)
    cut_w = int(W * cut_rat)
    cut_h = int(H * cut_rat)
    cx, cy = np.random.randint(W), np.random.randint(H)
    bbx1 = np.clip(cx - cut_w // 2, 0, W)
    bby1 = np.clip(cy - cut_h // 2, 0, H)
    bbx2 = np.clip(cx + cut_w // 2, 0, W)
    bby2 = np.clip(cy + cut_h // 2, 0, H)
    x[:, :, bby1:bby2, bbx1:bbx2] = x[index, :, bby1:bby2, bbx1:bbx2]
    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (W * H))
    y_a, y_b = y, y[index]
    return x, y_a, y_b, lam


def mixup_cutmix_criterion(criterion, preds, y_a, y_b, lam):
    """Mixup / CutMix åŠ æƒæŸå¤±"""
    return lam * criterion(preds, y_a) + (1 - lam) * criterion(preds, y_b)


# ============================================================
# å…¼å®¹æ—§æ¥å£ï¼ˆä¾› main.py è°ƒç”¨ï¼‰
# ============================================================
def augment_dataset(input_dir: str,
                    output_dir: str,
                    augmentations_per_image: int = 3,
                    seed: int = 42,
                    dataset: str = "cifar100") -> None:
    """
    å…¼å®¹ä¸»ç¨‹åºæ¥å£çš„å¢å¼ºå…¥å£å‡½æ•°ã€‚
    """
    augmenter = ImageAugmenter(
        augmentations_per_image=augmentations_per_image,
        seed=seed,
        save_original=True,
        dataset=dataset
    )
    augmenter.process_directory(input_dir, output_dir)
